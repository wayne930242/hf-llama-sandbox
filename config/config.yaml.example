model:
  name: "perplexity-ai/r1-1776-distill-llama-70b"
  local_path: null # If using local weights, fill in the path, otherwise keep it null

inference:
  max_length: 1024
  temperature: 0.5
  top_k: 40
  top_p: 0.9
